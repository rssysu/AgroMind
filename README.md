# AgroMind

A comprehensive agricultural remote sensing benchmark covering four task dimensions: Spatial Perception, Object Understanding, Scene Understanding, and Scene Reasoning, with a total of 13 task types, ranging from crop identification and health monitoring to environmental analysis. 

![License](https://img.shields.io/badge/license-CC%20BY--SA%204.0-lightgrey)

## ğŸ”— Link

- **GitHub Pages**: https://rssysu.github.io/AgroMind/
- **Paper(PDF)**: https://arxiv.org/abs/2505.12207
- **Dataset**: https://huggingface.co/datasets/AgroMind/AgroMind
- **Code**: https://github.com/rssysu/AgroMind

## ğŸ“‚ Structure

```plaintext
AgroMind/
â”œâ”€â”€ AgroMind/
â”‚   â”œâ”€â”€ models/                 # LLMs    
â”‚   â”œâ”€â”€ utils/      
â”‚   â””â”€â”€ eval.py     
â”œâ”€â”€ QA_Pairs/                   # Tasks
â”‚   â”œâ”€â”€ Spatial Perception/
â”‚   â”œâ”€â”€ Object Understanding/
â”‚   â”œâ”€â”€ Scene Understanding/   
â”‚   â””â”€â”€ Scene Reasoning/
â”œâ”€â”€ static/          
â”‚   â”œâ”€â”€ css/         
â”‚   â”œâ”€â”€ images/                  # data examples
â”‚   â””â”€â”€ js/          
â”œâ”€â”€ .nojekyll    
â”œâ”€â”€ conceptual.pdf               # Project poster
â”œâ”€â”€ README.md                    # introduction
â”œâ”€â”€ index.html                   # GitHub-Page
â””â”€â”€ test.txt                     # just for testing
```

## ğŸ“Œ Key Features
- **Multidimensional Evaluation**
  - ğŸŒ Spatial Perception
  - ğŸ” Object Understanding
  - ğŸï¸ Scene Understanding
  - ğŸ¤– Scene Reasoning

- **Technical Specifications**
  - 13 specialized agricultural tasks
  - Multimodal data support 

## Dataset
{
  "metadata": {
    "major_task": "Spatial Perception",  // å¤§ä»»åŠ¡ç±»å‹
    "minor_task": "Boundary Detection",   // å­ä»»åŠ¡ç±»å‹
    "sensor_type": "satellite"            // ä¼ æ„Ÿå™¨ç±»å‹
  },
  "items": [
    {
      "qid": "SP-BD-001",                // é—®é¢˜å”¯ä¸€æ ‡è¯†ç¬¦
      "image_path": "images/satellite/field_001.png",
      "question": "Find the boundaries of cultivated land",
      "answer": {
        "type": "coordinate",
        "value": [0.12, 0.45, 0.87, 0.92]  // [xmin, ymin, xmax, ymax]
      }
    }
  ]
}


## ğŸ“œ Cite
```plaintext
@misc{li2025largemultimodalmodelsunderstand,
      title={Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind}, 
      author={Qingmei Li and Yang Zhang and Zurong Mai and Yuhang Chen and Shuohong Lou and Henglian Huang and Jiarui Zhang and Zhiwei Zhang and Yibin Wen and Weijia Li and Haohuan Fu and Jianxi Huang and Juepeng Zheng},
      year={2025},
      eprint={2505.12207},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.12207}, 
}
```
