# AgroMind

A comprehensive agricultural remote sensing benchmark covering four task dimensions: Spatial Perception, Object Understanding, Scene Understanding, and Scene Reasoning, with a total of 13 task types, ranging from crop identification and health monitoring to environmental analysis. 

![License](https://img.shields.io/badge/license-CC%20BY--SA%204.0-lightgrey)

## ðŸ”— Link

- **GitHub Pages**: https://rssysu.github.io/AgroMind/
- **Paper(PDF)**: https://arxiv.org/abs/2505.12207
- **Dataset**: https://huggingface.co/datasets/AgroMind/AgroMind
- **Code**: https://github.com/AgroIntelligence/AgroMind



## ðŸ“‚ Structure

```plaintext
AgroMind/
â”œâ”€â”€ index.html       # Homepage
â”œâ”€â”€ conceptual.pdf   # Poster
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/         # Stylesheets
â”‚   â”œâ”€â”€ js/          # JavaScript files
â”‚   â””â”€â”€ images/      # Images and favicon
â””â”€â”€ README.md        # Project description (this file)
```





## ðŸ“œ Cite
@misc{li2025largemultimodalmodelsunderstand,
      title={Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind}, 
      author={Qingmei Li and Yang Zhang and Zurong Mai and Yuhang Chen and Shuohong Lou and Henglian Huang and Jiarui Zhang and Zhiwei Zhang and Yibin Wen and Weijia Li and Haohuan Fu and Jianxi Huang and Juepeng Zheng},
      year={2025},
      eprint={2505.12207},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.12207}, 
}

